{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 714,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08403361344537816,
      "grad_norm": 30.0501651763916,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 16.5429,
      "step": 20
    },
    {
      "epoch": 0.16806722689075632,
      "grad_norm": 30.77781105041504,
      "learning_rate": 3.6e-05,
      "loss": 10.5761,
      "step": 40
    },
    {
      "epoch": 0.25210084033613445,
      "grad_norm": 0.4458112418651581,
      "learning_rate": 5.500000000000001e-05,
      "loss": 1.5144,
      "step": 60
    },
    {
      "epoch": 0.33613445378151263,
      "grad_norm": 0.2766619026660919,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.4339,
      "step": 80
    },
    {
      "epoch": 0.42016806722689076,
      "grad_norm": 0.27130839228630066,
      "learning_rate": 9.5e-05,
      "loss": 0.3113,
      "step": 100
    },
    {
      "epoch": 0.5042016806722689,
      "grad_norm": 0.2382478564977646,
      "learning_rate": 9.755700325732899e-05,
      "loss": 0.2506,
      "step": 120
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.22369031608104706,
      "learning_rate": 9.429967426710097e-05,
      "loss": 0.2175,
      "step": 140
    },
    {
      "epoch": 0.6722689075630253,
      "grad_norm": 0.26156625151634216,
      "learning_rate": 9.104234527687297e-05,
      "loss": 0.2026,
      "step": 160
    },
    {
      "epoch": 0.7563025210084033,
      "grad_norm": 0.24935473501682281,
      "learning_rate": 8.778501628664495e-05,
      "loss": 0.209,
      "step": 180
    },
    {
      "epoch": 0.8403361344537815,
      "grad_norm": 0.24477441608905792,
      "learning_rate": 8.452768729641695e-05,
      "loss": 0.1909,
      "step": 200
    },
    {
      "epoch": 0.9243697478991597,
      "grad_norm": 0.25085029006004333,
      "learning_rate": 8.127035830618893e-05,
      "loss": 0.1749,
      "step": 220
    },
    {
      "epoch": 1.0084033613445378,
      "grad_norm": 0.30010324716567993,
      "learning_rate": 7.801302931596091e-05,
      "loss": 0.177,
      "step": 240
    },
    {
      "epoch": 1.092436974789916,
      "grad_norm": 0.3221321702003479,
      "learning_rate": 7.47557003257329e-05,
      "loss": 0.1665,
      "step": 260
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.30070167779922485,
      "learning_rate": 7.149837133550489e-05,
      "loss": 0.1641,
      "step": 280
    },
    {
      "epoch": 1.2605042016806722,
      "grad_norm": 0.2735533118247986,
      "learning_rate": 6.824104234527687e-05,
      "loss": 0.159,
      "step": 300
    },
    {
      "epoch": 1.3445378151260505,
      "grad_norm": 0.3229941129684448,
      "learning_rate": 6.498371335504886e-05,
      "loss": 0.1532,
      "step": 320
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.3661092519760132,
      "learning_rate": 6.172638436482085e-05,
      "loss": 0.1605,
      "step": 340
    },
    {
      "epoch": 1.5126050420168067,
      "grad_norm": 0.3945411145687103,
      "learning_rate": 5.846905537459284e-05,
      "loss": 0.1564,
      "step": 360
    },
    {
      "epoch": 1.596638655462185,
      "grad_norm": 0.570827305316925,
      "learning_rate": 5.5211726384364825e-05,
      "loss": 0.1533,
      "step": 380
    },
    {
      "epoch": 1.680672268907563,
      "grad_norm": 0.3824499249458313,
      "learning_rate": 5.1954397394136814e-05,
      "loss": 0.1541,
      "step": 400
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.3599701225757599,
      "learning_rate": 4.86970684039088e-05,
      "loss": 0.1558,
      "step": 420
    },
    {
      "epoch": 1.8487394957983194,
      "grad_norm": 0.42110809683799744,
      "learning_rate": 4.543973941368078e-05,
      "loss": 0.1435,
      "step": 440
    },
    {
      "epoch": 1.9327731092436975,
      "grad_norm": 0.4714977443218231,
      "learning_rate": 4.2182410423452775e-05,
      "loss": 0.1497,
      "step": 460
    },
    {
      "epoch": 2.0168067226890756,
      "grad_norm": 0.4051511883735657,
      "learning_rate": 3.892508143322476e-05,
      "loss": 0.1432,
      "step": 480
    },
    {
      "epoch": 2.100840336134454,
      "grad_norm": 0.49216780066490173,
      "learning_rate": 3.566775244299674e-05,
      "loss": 0.1249,
      "step": 500
    },
    {
      "epoch": 2.184873949579832,
      "grad_norm": 0.4720974266529083,
      "learning_rate": 3.241042345276873e-05,
      "loss": 0.1191,
      "step": 520
    },
    {
      "epoch": 2.26890756302521,
      "grad_norm": 0.5125998854637146,
      "learning_rate": 2.915309446254072e-05,
      "loss": 0.1319,
      "step": 540
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.3651016652584076,
      "learning_rate": 2.5895765472312705e-05,
      "loss": 0.124,
      "step": 560
    },
    {
      "epoch": 2.4369747899159666,
      "grad_norm": 0.4844094514846802,
      "learning_rate": 2.263843648208469e-05,
      "loss": 0.1161,
      "step": 580
    },
    {
      "epoch": 2.5210084033613445,
      "grad_norm": 0.49575504660606384,
      "learning_rate": 1.938110749185668e-05,
      "loss": 0.1193,
      "step": 600
    },
    {
      "epoch": 2.6050420168067228,
      "grad_norm": 0.5583649277687073,
      "learning_rate": 1.6123778501628666e-05,
      "loss": 0.1325,
      "step": 620
    },
    {
      "epoch": 2.689075630252101,
      "grad_norm": 0.5268058776855469,
      "learning_rate": 1.2866449511400652e-05,
      "loss": 0.1164,
      "step": 640
    },
    {
      "epoch": 2.773109243697479,
      "grad_norm": 0.5297697186470032,
      "learning_rate": 9.609120521172639e-06,
      "loss": 0.1233,
      "step": 660
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.5093491077423096,
      "learning_rate": 6.351791530944626e-06,
      "loss": 0.1233,
      "step": 680
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.47115442156791687,
      "learning_rate": 3.0944625407166126e-06,
      "loss": 0.1214,
      "step": 700
    }
  ],
  "logging_steps": 20,
  "max_steps": 714,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.263951629254656e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
